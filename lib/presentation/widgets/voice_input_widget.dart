import 'package:flutter/material.dart';
import 'package:hooks_riverpod/hooks_riverpod.dart';
import 'package:flutter_hooks/flutter_hooks.dart';
import '../providers/audio_stream_provider.dart';
import '../providers/connection_provider.dart';
import '../../core/constants/audio_constants.dart';
import '../../data/models/websocket_state.dart';
import '../../core/services/audio/voice_interrupt_service.dart';
import '../../core/utils/loggers.dart';

/// è¯­éŸ³è¾“å…¥ç»„ä»¶
/// æä¾›æŒ‰ä½è¯´è¯å’Œå½•åˆ¶çŠ¶æ€å¯è§†åŒ–åŠŸèƒ½
class VoiceInputWidget extends HookConsumerWidget {
  final VoidCallback? onVoiceStart;
  final VoidCallback? onVoiceEnd;
  final VoidCallback? onVoiceCancel;
  final bool isEnabled;
  final double size;

  const VoiceInputWidget({
    super.key,
    this.onVoiceStart,
    this.onVoiceEnd,
    this.onVoiceCancel,
    this.isEnabled = true,
    this.size = 60.0,
  });

  @override
  Widget build(BuildContext context, WidgetRef ref) {
    final streamState = ref.watch(audioStreamProvider);
    final streamNotifier = ref.watch(audioStreamProvider.notifier);
    final connectionState = ref.watch(connectionManagerProvider);
    
    // æŒ‰ä½çŠ¶æ€
    final isPressed = useState(false);
    final pressStartTime = useState<DateTime?>(null);
    
    // ç§»é™¤è‡ªåŠ¨åˆå§‹åŒ–é€»è¾‘ - ç°åœ¨åœ¨åº”ç”¨å¯åŠ¨æ—¶é¢„åˆå§‹åŒ–
    
    // è®¡ç®—æ˜¯å¦å¯ä»¥ä½¿ç”¨è¯­éŸ³åŠŸèƒ½
    final canUseVoice = connectionState.webSocketState.isConnected &&
        connectionState.handshakeResult.isCompleted &&
        streamState.isInitialized &&
        streamState.hasPermission &&
        isEnabled;

    // ç›‘å¬æµä¼ è¾“çŠ¶æ€å˜åŒ–
    useEffect(() {
      if (streamState.isStreaming && !isPressed.value) {
        // å¦‚æœä¸æ˜¯æŒ‰ä½çŠ¶æ€ä½†åœ¨æµä¼ è¾“ï¼Œè¯´æ˜å‡ºç°äº†çŠ¶æ€ä¸åŒæ­¥
        streamNotifier.stopStreaming();
      }
      return null;
    }, [streamState.isStreaming, isPressed.value]);

    return GestureDetector(
      onTapDown: canUseVoice ? (details) => _onPressStart(
        context, ref, streamNotifier, streamState, isPressed, pressStartTime
      ) : null,
      onTapUp: (details) => _onPressEnd(
        context, ref, streamNotifier, isPressed, pressStartTime
      ),
      onTapCancel: () => _onPressCancel(
        context, ref, streamNotifier, isPressed, pressStartTime
      ),
      child: AnimatedContainer(
        duration: const Duration(milliseconds: 200),
        width: size,
        height: size,
        decoration: BoxDecoration(
          color: _getButtonColor(streamState, isPressed.value, canUseVoice),
          shape: BoxShape.circle,
          boxShadow: _getButtonShadow(streamState, isPressed.value),
        ),
        child: Stack(
          alignment: Alignment.center,
          children: [
            // å½•åˆ¶çŠ¶æ€æŒ‡ç¤ºå™¨
            if (streamState.isStreaming)
              _buildRecordingIndicator(context, streamState),
            
            // ä¸»å›¾æ ‡
            Icon(
              _getButtonIcon(streamState, canUseVoice),
              color: Colors.white,
              size: size * 0.4,
            ),
            
            // ä¸å¯ç”¨çŠ¶æ€é®ç½©
            if (!canUseVoice)
              Container(
                width: size,
                height: size,
                decoration: BoxDecoration(
                  color: Colors.black.withValues(alpha: 0.3),
                  shape: BoxShape.circle,
                ),
              ),
          ],
        ),
      ),
    );
  }

  /// è·å–æŒ‰é’®é¢œè‰²
  Color _getButtonColor(AudioStreamState state, bool isPressed, bool canUse) {
    if (!canUse) return Colors.grey;
    
    if (state.isStreaming) {
      return isPressed ? Colors.red.shade600 : Colors.red.shade500;
    }
    
    if (isPressed) {
      return Colors.blue.shade600;
    }
    
    return Colors.blue.shade500;
  }

  /// è·å–æŒ‰é’®é˜´å½±
  List<BoxShadow> _getButtonShadow(AudioStreamState state, bool isPressed) {
    if (state.isStreaming) {
      return [
        BoxShadow(
          color: Colors.red.withValues(alpha: 0.5),
          blurRadius: isPressed ? 12 : 8,
          offset: const Offset(0, 2),
        ),
      ];
    }
    
    return [
      BoxShadow(
        color: Colors.blue.withValues(alpha: 0.3),
        blurRadius: isPressed ? 12 : 8,
        offset: const Offset(0, 2),
      ),
    ];
  }

  /// è·å–æŒ‰é’®å›¾æ ‡
  IconData _getButtonIcon(AudioStreamState state, bool canUse) {
    if (!canUse) return Icons.mic_off;
    if (state.isStreaming) return Icons.mic;
    return Icons.mic_none;
  }

  /// æ„å»ºå½•åˆ¶æŒ‡ç¤ºå™¨
  Widget _buildRecordingIndicator(BuildContext context, AudioStreamState state) {
    return TweenAnimationBuilder<double>(
      duration: const Duration(milliseconds: 1000),
      tween: Tween(begin: 0.0, end: 1.0),
      builder: (context, value, child) {
        return CustomPaint(
          painter: RecordingIndicatorPainter(
            progress: value,
            color: Colors.white.withValues(alpha: 0.8),
          ),
          size: Size(size, size),
        );
      },
    );
  }

  /// æŒ‰ä¸‹å¼€å§‹
  void _onPressStart(
    BuildContext context,
    WidgetRef ref,
    AudioStreamNotifier streamNotifier,
    AudioStreamState streamState,
    ValueNotifier<bool> isPressed,
    ValueNotifier<DateTime?> pressStartTime,
  ) async {
    Loggers.ui.userAction('è¯­éŸ³è¾“å…¥æŒ‰ä¸‹å¼€å§‹');
    
    isPressed.value = true;
    pressStartTime.value = DateTime.now();
    
    // ç¡®ä¿å·²åˆå§‹åŒ–ï¼ˆåº”ç”¨å¯åŠ¨æ—¶åº”è¯¥å·²ç»åˆå§‹åŒ–äº†ï¼‰
    if (!streamState.isInitialized) {
      final success = await streamNotifier.initializeStreaming();
      if (!success) {
        Loggers.ui.severe('è¯­éŸ³è¾“å…¥åˆå§‹åŒ–å¤±è´¥');
        if (context.mounted) {
          _showError(context, 'è¯­éŸ³åŠŸèƒ½åˆå§‹åŒ–å¤±è´¥');
        }
        isPressed.value = false;
        pressStartTime.value = null;
        return;
      }
    }

    // ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ï¼šè¯­éŸ³å½•åˆ¶å‰è‡ªåŠ¨æ‰“æ–­æ­£åœ¨æ’­æ”¾çš„AIè¯­éŸ³
    // ç”¨æˆ·å¼€å§‹è¯´è¯æ—¶ï¼Œç«‹å³åœæ­¢AIæ­£åœ¨æ’­æ”¾çš„è¯­éŸ³
    try {
      Loggers.ui.info('è¯­éŸ³å½•åˆ¶å‰æ‰§è¡Œè‡ªåŠ¨è¯­éŸ³æ‰“æ–­');
      final voiceInterruptService = ref.read(voiceInterruptServiceProvider);
      await voiceInterruptService.autoInterruptBeforeSend();
    } catch (e) {
      Loggers.ui.severe('è¯­éŸ³å½•åˆ¶å‰çš„æ‰“æ–­å¤±è´¥', e);
      // ç»§ç»­å½•åˆ¶æµç¨‹ï¼Œä¸å› ä¸ºæ‰“æ–­å¤±è´¥è€Œé˜»æ­¢ç”¨æˆ·å½•åˆ¶
    }

    // å¼€å§‹å½•åˆ¶
    final success = await streamNotifier.startStreaming();
    if (!success) {
      Loggers.ui.severe('å¼€å§‹å½•åˆ¶å¤±è´¥');
      if (context.mounted) {
        _showError(context, 'å¼€å§‹å½•åˆ¶å¤±è´¥');
      }
      isPressed.value = false;
      pressStartTime.value = null;
      return;
    }

    Loggers.ui.info('å½•åˆ¶å¼€å§‹æˆåŠŸ');
    onVoiceStart?.call();
    
    // è§¦è§‰åé¦ˆ
    // HapticFeedback.lightImpact();
  }

  /// æŒ‰ä¸‹ç»“æŸ
  void _onPressEnd(
    BuildContext context,
    WidgetRef ref,
    AudioStreamNotifier streamNotifier,
    ValueNotifier<bool> isPressed,
    ValueNotifier<DateTime?> pressStartTime,
  ) async {
    Loggers.ui.userAction('è¯­éŸ³è¾“å…¥æŒ‰ä¸‹ç»“æŸ');
    
    if (!isPressed.value) return;
    
    isPressed.value = false;
    final startTime = pressStartTime.value;
    pressStartTime.value = null;

    // æ£€æŸ¥å½•åˆ¶æ—¶é•¿
    if (startTime != null) {
      final duration = DateTime.now().difference(startTime);
      if (duration.inMilliseconds < 500) {
        Loggers.ui.info('å½•åˆ¶æ—¶é—´è¿‡çŸ­ï¼Œå–æ¶ˆå½•åˆ¶');
        await streamNotifier.stopStreaming();
        
        // ğŸ¯ é€šçŸ¥è¯­éŸ³æ‰“æ–­æœåŠ¡å½•åˆ¶å·²å–æ¶ˆï¼ˆæ—¶é—´è¿‡çŸ­ï¼‰
        try {
          final voiceInterruptService = ref.read(voiceInterruptServiceProvider);
          await voiceInterruptService.cancelRecording(reason: 'duration_too_short');
        } catch (e) {
          Loggers.ui.severe('é€šçŸ¥è¯­éŸ³æ‰“æ–­æœåŠ¡å¤±è´¥', e);
        }
        
        if (context.mounted) {
          _showError(context, 'å½•åˆ¶æ—¶é—´è¿‡çŸ­ï¼Œè¯·é•¿æŒ‰å½•åˆ¶');
        }
        onVoiceCancel?.call();
        return;
      }
    }

    // åœæ­¢å½•åˆ¶
    final success = await streamNotifier.stopStreaming();
    if (!success) {
      Loggers.ui.severe('åœæ­¢å½•åˆ¶å¤±è´¥');
      if (context.mounted) {
        _showError(context, 'åœæ­¢å½•åˆ¶å¤±è´¥');
      }
      return;
    }

    Loggers.ui.info('å½•åˆ¶ç»“æŸæˆåŠŸ');
    onVoiceEnd?.call();
  }

  /// æŒ‰ä¸‹å–æ¶ˆ
  void _onPressCancel(
    BuildContext context,
    WidgetRef ref,
    AudioStreamNotifier streamNotifier,
    ValueNotifier<bool> isPressed,
    ValueNotifier<DateTime?> pressStartTime,
  ) async {
    Loggers.ui.userAction('è¯­éŸ³è¾“å…¥æŒ‰ä¸‹å–æ¶ˆ');
    
    if (!isPressed.value) return;
    
    isPressed.value = false;
    pressStartTime.value = null;

    // å–æ¶ˆå½•åˆ¶
    await streamNotifier.stopStreaming();
    
    // ğŸ¯ é€šçŸ¥è¯­éŸ³æ‰“æ–­æœåŠ¡å½•åˆ¶å·²å–æ¶ˆ
    try {
      final voiceInterruptService = ref.read(voiceInterruptServiceProvider);
      await voiceInterruptService.cancelRecording(reason: 'user_cancel');
    } catch (e) {
      Loggers.ui.severe('é€šçŸ¥è¯­éŸ³æ‰“æ–­æœåŠ¡å¤±è´¥', e);
    }
    
    Loggers.ui.info('å½•åˆ¶å·²å–æ¶ˆ');
    onVoiceCancel?.call();
  }

  /// æ˜¾ç¤ºé”™è¯¯æç¤º
  void _showError(BuildContext context, String message) {
    if (context.mounted) {
      ScaffoldMessenger.of(context).showSnackBar(
        SnackBar(
          content: Text(message),
          backgroundColor: Colors.red,
          duration: const Duration(seconds: 2),
        ),
      );
    }
  }
}

/// å½•åˆ¶æŒ‡ç¤ºå™¨ç”»ç¬”
class RecordingIndicatorPainter extends CustomPainter {
  final double progress;
  final Color color;

  RecordingIndicatorPainter({
    required this.progress,
    required this.color,
  });

  @override
  void paint(Canvas canvas, Size size) {
    final center = Offset(size.width / 2, size.height / 2);
    final radius = size.width / 2;
    
    // ç»˜åˆ¶è„‰å†²åœ†ç¯
    final paint = Paint()
      ..color = color.withValues(alpha: 0.3 + 0.4 * progress)
      ..style = PaintingStyle.stroke
      ..strokeWidth = 2;
    
    canvas.drawCircle(center, radius * (0.8 + 0.2 * progress), paint);
    
    // ç»˜åˆ¶å†…åœ†ç‚¹
    final dotPaint = Paint()
      ..color = color
      ..style = PaintingStyle.fill;
    
    canvas.drawCircle(center, 2, dotPaint);
  }

  @override
  bool shouldRepaint(covariant RecordingIndicatorPainter oldDelegate) {
    return oldDelegate.progress != progress || oldDelegate.color != color;
  }
}

/// è¯­éŸ³çŠ¶æ€æŒ‡ç¤ºå™¨
class VoiceStatusIndicator extends StatelessWidget {
  final AudioStreamState state;
  final double size;

  const VoiceStatusIndicator({
    super.key,
    required this.state,
    this.size = 80.0,
  });

  @override
  Widget build(BuildContext context) {
    return Container(
      width: size,
      height: size,
      decoration: BoxDecoration(
        color: _getStatusColor(),
        shape: BoxShape.circle,
        boxShadow: [
          BoxShadow(
            color: _getStatusColor().withValues(alpha: 0.3),
            blurRadius: 8,
            offset: const Offset(0, 2),
          ),
        ],
      ),
      child: Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
            Icon(
              _getStatusIcon(),
              color: Colors.white,
              size: size * 0.3,
            ),
            const SizedBox(height: 4),
            Text(
              _getStatusText(),
              style: TextStyle(
                color: Colors.white,
                fontSize: 14, // ä½¿ç”¨å›ºå®šå­—ä½“ï¼Œä¼šè¢«å…¨å±€fontScaleç¼©æ”¾
                fontWeight: FontWeight.w500,
              ),
            ),
          ],
        ),
      ),
    );
  }

  Color _getStatusColor() {
    switch (state.status) {
      case AudioConstants.stateIdle:
        return Colors.grey;
      case AudioConstants.stateRecording:
        return Colors.green;
      case AudioConstants.stateProcessing:
        return Colors.orange;
      case AudioConstants.stateError:
        return Colors.red;
      default:
        return Colors.grey;
    }
  }

  IconData _getStatusIcon() {
    switch (state.status) {
      case AudioConstants.stateIdle:
        return Icons.mic_none;
      case AudioConstants.stateRecording:
        return Icons.mic;
      case AudioConstants.stateProcessing:
        return Icons.hourglass_empty;
      case AudioConstants.stateError:
        return Icons.error;
      default:
        return Icons.help;
    }
  }

  String _getStatusText() {
    switch (state.status) {
      case AudioConstants.stateIdle:
        return 'å¾…æœº';
      case AudioConstants.stateRecording:
        return 'å½•åˆ¶ä¸­';
      case AudioConstants.stateProcessing:
        return 'å¤„ç†ä¸­';
      case AudioConstants.stateError:
        return 'é”™è¯¯';
      default:
        return 'æœªçŸ¥';
    }
  }
}