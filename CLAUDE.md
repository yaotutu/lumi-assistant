# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Lumi Assistant is a Flutter-based intelligent voice assistant client using a milestone-driven development approach. The project is currently in **Phase 1** (text chat functionality) with 10 planned milestones, each requiring user verification before proceeding.

**Current Status**: Milestone 3 (Hello handshake flow) - Successfully completed. Ready for Milestone 4 (Basic UI framework).

## Architecture

The project uses **modern Flutter architecture** rejecting traditional MVVM in favor of:
- **Layered Architecture**: Presentation â†’ Application â†’ Data â†’ Infrastructure
- **Declarative State Management**: flutter_hooks + hooks_riverpod
- **Compositional Design**: Small, focused, reusable components
- **Functional Programming**: Hooks-based approach with pure functions

Key architectural principles:
- Composition over inheritance
- Single-directional data flow: `User Action â†’ Provider â†’ Service â†’ Repository â†’ DataSource`
- Atomic UI components with clear separation of concerns
- State isolation using Riverpod providers, not traditional Provider pattern

## Directory Structure

```
lib/
â”œâ”€â”€ core/                    # Core utilities, constants, services
â”œâ”€â”€ data/                   # Data layer (models, repositories, datasources)
â”œâ”€â”€ domain/                 # Business layer (entities, repository interfaces, use cases)
â””â”€â”€ presentation/           # UI layer (providers, pages, widgets)
    â”œâ”€â”€ pages/               # Page-oriented organization
    â”‚   â””â”€â”€ home/            # Home page and its components
    â”‚       â”œâ”€â”€ home_page.dart
    â”‚       â””â”€â”€ widgets/     # Home page specific widgets
    â”‚           â”œâ”€â”€ background_layer.dart
    â”‚           â”œâ”€â”€ app_status_bar.dart
    â”‚           â”œâ”€â”€ time_panel.dart
    â”‚           â”œâ”€â”€ interaction_layer.dart
    â”‚           â””â”€â”€ floating_actions.dart
    â”œâ”€â”€ widgets/             # Shared widgets across pages
    â””â”€â”€ themes/              # App themes and styling
```

### File Organization Rules

**Page-Oriented Structure**: Each page should have its own directory containing:
- Main page file (e.g., `home_page.dart`)
- `widgets/` subdirectory for page-specific components
- Any page-specific services, models, or utilities

**Shared Components**: Common widgets used across multiple pages go in `presentation/widgets/`

**Benefits**:
- Clear separation of concerns per page
- Easy to locate and maintain page-specific code
- Better scalability for large applications
- Intuitive file organization

## Development Commands

### Environment Setup
```bash
# Check Flutter environment
flutter doctor

# Install dependencies
flutter pub get

# Run the app (preferred device: YT3002)
flutter run -d 1W11833968

# Alternative: List all devices first
flutter devices
```

### Device Configuration
**Preferred Testing Device**: YT3002 (Device ID: 1W11833968)
- Platform: Android 7.0 (API 24)
- Architecture: android-arm64
- Usage: Primary development and testing device

When multiple devices are connected, always use the `-d 1W11833968` flag to target the YT3002 device specifically.

### Quick Commands for YT3002 Device
```bash
# Quick run on YT3002 (preferred device)
flutter run -d 1W11833968

# Hot reload on YT3002
flutter run -d 1W11833968 --hot

# Build and run debug APK on YT3002
flutter run -d 1W11833968 --debug

# Clean build on YT3002
flutter clean && flutter pub get && flutter run -d 1W11833968
```

### Testing
```bash
# Run all tests
flutter test

# Run specific test directory
flutter test test/presentation/providers/

# Generate test coverage
flutter test --coverage
```

### Building
```bash
# Build APK for release
flutter build apk --release

# Build App Bundle
flutter build appbundle --release

# Analyze code
flutter analyze
```

## Backend Integration

**Python Backend Server**: `/Users/yaotutu/Desktop/code/xiaozhi-esp32-server/main/xiaozhi-server`
**WebSocket**: `ws://192.168.110.199:8000/` (å›ºå®šä½¿ç”¨PythonæœåŠ¡å™¨)
**HTTP API**: `http://192.168.110.199:8000/api` (å›ºå®šä½¿ç”¨PythonæœåŠ¡å™¨)
**Authentication**: Bearer Token + Device-ID headers

Message types: `hello` (handshake), `chat` (text), `listen` (voice), `image` (vision)

**æœåŠ¡å™¨é…ç½®è¯´æ˜**ï¼š
- å¼€å‘ç¯å¢ƒï¼šä½¿ç”¨å±€åŸŸç½‘IP `192.168.110.199` (PythonæœåŠ¡å™¨)
- ä¸æ”¯æŒæœåŠ¡å™¨åˆ‡æ¢åŠŸèƒ½ï¼Œç»Ÿä¸€ä½¿ç”¨Pythonåç«¯
- é…ç½®ä½ç½®ï¼š`lib/core/constants/api_constants.dart`

## Reference Implementation

**Android Client**: `/Users/yaotutu/Desktop/code/xiaozhi-android-client`
- Use this Android client as the main reference for implementation patterns
- Follow similar WebSocket handling and UI interaction patterns
- Reference authentication and message handling approaches

## Project Memory and Context

### Reference Projects Overview

#### Android Client (`/Users/yaotutu/Desktop/code/xiaozhi-android-client`)
**Project Type**: Flutter application (not native Android)
**Architecture**: Provider-based state management with service layer pattern
**Key Features**:
- Real-time WebSocket communication with event-driven architecture
- Opus audio codec integration for voice processing
- Multi-conversation management with persistent storage
- Material Design 3 UI with neumorphism elements
- Voice call interface with audio visualization

**Key Implementation Patterns to Reference**:
```dart
// Event-driven WebSocket architecture
enum XiaozhiEventType { connected, disconnected, message, error, binaryMessage }

// Service layer pattern
class XiaozhiService {
  static final XiaozhiService instance = XiaozhiService._internal();
  late XiaozhiWebSocketManager _webSocketManager;
}

// Audio processing pipeline
class AudioUtil {
  static const int SAMPLE_RATE = 16000;
  static const int CHANNELS = 1;
  static const int FRAME_DURATION = 60; // milliseconds
}
```

#### Python Backend (`/Users/yaotutu/Desktop/code/xiaozhi-esp32-server/main/xiaozhi-server`)
**Project Type**: AsyncIO-based Python server with comprehensive AI integration
**Architecture**: Provider pattern with plugin system for AI services
**Core Features**:
- WebSocket server for real-time audio streaming
- HTTP API for OTA updates and vision analysis
- Multi-modal AI: ASR, LLM, TTS, Vision, VAD
- IoT device control with MCP protocol
- Function calling and plugin system

**API Documentation Source**: All interface specifications are derived from this backend's `/docs` directory

### WebSocket Protocol (from Python Backend)

#### Connection Flow:
1. **Client Connection**: `ws://192.168.110.199:8000/xiaozhi/v1/`
2. **Authentication**: Headers (`device-id`, `Authorization: Bearer token`)
3. **Handshake**: `hello` message exchange with session management
4. **Audio Streaming**: Binary Opus frames + JSON text messages

#### Message Types:
```json
// Client Hello
{
  "type": "hello",
  "version": 1,
  "transport": "websocket",
  "audio_params": {
    "format": "opus",
    "sample_rate": 16000,
    "channels": 1,
    "frame_duration": 60
  }
}

// Server Hello Response
{
  "type": "hello",
  "session_id": "uuid-generated-by-server",
  "version": 1,
  "transport": "websocket",
  "audio_params": { ... }
}

// Listen Control
{
  "type": "listen",
  "state": "start|stop|detect",
  "mode": "auto|manual",
  "text": "optional text input"
}

// TTS Response
{
  "type": "tts",
  "state": "start|sentence_start|sentence_end|stop",
  "text": "Generated response text",
  "session_id": "uuid"
}

// STT Recognition
{
  "type": "stt",
  "text": "Recognized speech text",
  "confidence": 0.95,
  "is_final": true,
  "session_id": "uuid"
}
```

### HTTP API Endpoints (from Python Backend)

#### OTA Updates:
```http
POST /xiaozhi/ota/
Headers: device-id, Authorization
Body: {"application": {"version": "1.0.0", "build": "timestamp"}}

Response: {
  "server_time": {"timestamp": 1699123456789, "timezone_offset": 480},
  "websocket": {"url": "ws://192.168.110.199:8000/xiaozhi/v1/"}
}
```

#### Vision Analysis:
```http
POST /mcp/vision/explain
Content-Type: multipart/form-data
Headers: Authorization, Device-Id
Form: question (text), image (file)

Response: {
  "success": true,
  "action": "RESPONSE",
  "response": "Image analysis result..."
}
```

### Audio Processing Specifications (from both projects)

#### Audio Format:
- **Codec**: Opus (libopus)
- **Sample Rate**: 16kHz
- **Channels**: Mono (1 channel)
- **Frame Duration**: 60ms
- **Bitrate**: Adaptive (8-64 kbps)

#### Processing Pipeline:
```
Microphone â†’ PCM16 â†’ Opus Encoder â†’ WebSocket Binary â†’ Server
Server â†’ Opus Audio â†’ WebSocket Binary â†’ Opus Decoder â†’ PCM â†’ Speaker
```

### Integration Patterns for Flutter

#### WebSocket Service Pattern (from Android Client):
```dart
class WebSocketService {
  late WebSocket _webSocket;
  final StreamController<XiaozhiEvent> _eventController = StreamController.broadcast();
  
  Future<void> connect(String url, Map<String, String> headers) async {
    _webSocket = await WebSocket.connect(url, headers: headers);
    _webSocket.listen(_onMessage, onError: _onError);
  }
  
  void sendHello() {
    final hello = {
      'type': 'hello',
      'version': 1,
      'transport': 'websocket',
      'audio_params': {
        'format': 'opus',
        'sample_rate': 16000,
        'channels': 1,
        'frame_duration': 60
      }
    };
    _webSocket.add(jsonEncode(hello));
  }
}
```

#### Provider Pattern (from Backend):
```dart
// AI Service Integration
abstract class ASRProvider {
  Future<String> speechToText(List<int> opusData, String sessionId);
}

abstract class LLMProvider {
  Stream<String> generateResponse(String sessionId, List<Map<String, dynamic>> dialogue);
}

abstract class TTSProvider {
  Future<Uint8List> textToSpeech(String text);
}
```

### Development Priorities (based on reference implementations)

#### Phase 1: Foundation (Current)
- âœ… WebSocket connection with authentication
- âœ… Basic hello handshake protocol
- âœ… Text message exchange
- âœ… Session management

#### Phase 2: Audio Integration
- ğŸ”„ Opus audio recording/encoding
- ğŸ”„ Audio streaming to server
- ğŸ”„ TTS audio reception/playback
- ğŸ”„ Real-time audio processing

#### Phase 3: Advanced Features
- â¸ï¸ Vision analysis integration
- â¸ï¸ Function calling display
- â¸ï¸ IoT device control UI
- â¸ï¸ Multi-conversation management

#### Phase 4: Production Features
- â¸ï¸ Error handling and reconnection
- â¸ï¸ Offline mode support
- â¸ï¸ Performance monitoring
- â¸ï¸ Voice call interface

### Key Learnings from Reference Projects

1. **Event-Driven Architecture**: Both projects use listener patterns for real-time communication
2. **Service Layer Separation**: Clear separation between UI and business logic
3. **Robust Audio Processing**: Comprehensive audio pipeline with proper resource management
4. **Session Management**: Proper handling of server sessions and reconnection
5. **Error Handling**: Graceful degradation and user-friendly error messages

### Migration Path (Android Client â†’ Current Flutter)

**State Management**: `Provider` â†’ `hooks_riverpod` (already implemented)
**Architecture**: `Traditional` â†’ `Clean Architecture` (partially implemented)
**Audio Processing**: `Simple` â†’ `Comprehensive Opus Pipeline` (to be implemented)
**UI Pattern**: `Material Design` â†’ `Material Design 3 + Neumorphism` (partially implemented)

## Milestone-Driven Development

**Critical**: This project follows strict milestone verification:
1. Each milestone must be fully completed before moving to next
2. User verification required after each milestone
3. No feature should be started without completing current milestone
4. All progress tracked in `docs/planning/MILESTONE_TRACKING.md`

**é‡Œç¨‹ç¢‘å®ŒæˆçŠ¶æ€**:
- âœ… é‡Œç¨‹ç¢‘1ï¼šé¡¹ç›®åŸºç¡€æ­å»º - å·²å®Œæˆ
- âœ… é‡Œç¨‹ç¢‘2ï¼šç½‘ç»œè¿æ¥åŸºç¡€ - å·²å®Œæˆ  
- âœ… é‡Œç¨‹ç¢‘3ï¼šHelloæ¡æ‰‹æµç¨‹ - å·²å®Œæˆ
- âœ… é‡Œç¨‹ç¢‘4ï¼šåŸºç¡€UIæ¡†æ¶ - å·²å®Œæˆ
- âœ… é‡Œç¨‹ç¢‘5ï¼šèŠå¤©ç•Œé¢åŸºç¡€ - å·²å®Œæˆ
- âœ… é‡Œç¨‹ç¢‘6ï¼šæ–‡å­—æ¶ˆæ¯å‘é€ - å·²å®Œæˆ
- â¸ï¸ é‡Œç¨‹ç¢‘7ï¼šLLMå“åº”å¤„ç† - ç­‰å¾…ä¸­

**å½“å‰çŠ¶æ€**: é‡Œç¨‹ç¢‘6å·²å®Œæˆï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µå¼€å‘

**ä¸‹ä¸€é˜¶æ®µä»»åŠ¡**ï¼ˆé‡Œç¨‹ç¢‘7ï¼šLLMå“åº”å¤„ç†ï¼‰:
- å®ç°æœåŠ¡å™¨å“åº”æ¶ˆæ¯æ¥æ”¶å’Œæ˜¾ç¤º
- å®Œå–„èŠå¤©æ¶ˆæ¯æµç®¡ç†
- å¤„ç†ä¸åŒç±»å‹çš„æœåŠ¡å™¨å“åº”
- å®ç°æ¶ˆæ¯çŠ¶æ€è¿½è¸ªå’Œé”™è¯¯å¤„ç†

## Code Patterns

### State Management
```dart
// Riverpod Provider with Hooks
final chatProvider = StateNotifierProvider<ChatNotifier, ChatState>((ref) {
  return ChatNotifier(ref.read(webSocketServiceProvider));
});

// Hook Consumer Widget
class ChatPage extends HookConsumerWidget {
  Widget build(BuildContext context, WidgetRef ref) {
    final chatState = ref.watch(chatProvider);
    final controller = useTextEditingController();
    // ...
  }
}
```

### Error Handling
Use custom exception types (`NetworkException`, `WebSocketException`) with centralized error handling via `ErrorHandler` class.

### File Naming
- snake_case for files: `chat_service.dart`
- PascalCase for classes: `ChatService`
- camelCase for variables/methods: `sendMessage`

## Documentation Structure

Important docs are organized in `docs/`:
- `planning/` - Project plans and milestone tracking
- `architecture/` - Technical architecture and specifications  
- `frontend/` - Development guidelines and best practices

**Always check milestone status** in `docs/planning/MILESTONE_TRACKING.md` before making changes.

### é¡¹ç›®è®°å¿†é‡è¦æé†’

1. **å‚è€ƒé¡¹ç›®ä½ç½®**ï¼š
   - Androidå®¢æˆ·ç«¯ï¼š`/Users/yaotutu/Desktop/code/xiaozhi-android-client`
   - Pythonåç«¯ï¼š`/Users/yaotutu/Desktop/code/xiaozhi-esp32-server/main/xiaozhi-server`

2. **APIæ–‡æ¡£æ¥æº**ï¼š
   - æ‰€æœ‰æ¥å£è§„èŒƒéƒ½æ¥è‡ªPythonåç«¯é¡¹ç›®çš„`docs/`ç›®å½•
   - WebSocketåè®®å’ŒHTTP APIçš„è¯¦ç»†å®šä¹‰åœ¨ä¸Šé¢çš„é¡¹ç›®è®°å¿†ä¸­

3. **å¼€å‘ä¼˜å…ˆçº§**ï¼š
   - å½“å‰é˜¶æ®µä¸»è¦å…³æ³¨æ–‡æœ¬èŠå¤©åŠŸèƒ½çš„å®Œå–„
   - éŸ³é¢‘åŠŸèƒ½åœ¨åç»­é˜¶æ®µå®ç°ï¼Œéœ€è¦å‚è€ƒAndroidå®¢æˆ·ç«¯çš„OpuséŸ³é¢‘å¤„ç†
   - å¤šæ¨¡æ€åŠŸèƒ½ï¼ˆè§†è§‰ã€IoTæ§åˆ¶ï¼‰å°†åœ¨æœ€åå®ç°

4. **æŠ€æœ¯æ¶æ„å¯¹é½**ï¼š
   - å½“å‰é¡¹ç›®ä½¿ç”¨çš„hooks_riverpodæ¯”Androidå®¢æˆ·ç«¯çš„Provideræ›´ç°ä»£
   - ä½†éœ€è¦å‚è€ƒAndroidå®¢æˆ·ç«¯çš„WebSocketäº‹ä»¶é©±åŠ¨æ¶æ„
   - éŸ³é¢‘å¤„ç†ç®¡é“éœ€è¦å®Œå…¨éµå¾ªAndroidå®¢æˆ·ç«¯çš„æ¨¡å¼

5. **å½“å‰å¼€å‘é‡ç‚¹**ï¼š
   - é‡Œç¨‹ç¢‘6å·²å®Œæˆæ–‡æœ¬æ¶ˆæ¯å‘é€åŠŸèƒ½
   - ä¸‹ä¸€æ­¥éœ€è¦å®ç°æœåŠ¡å™¨å“åº”æ¶ˆæ¯çš„å®Œæ•´å¤„ç†
   - é‡ç‚¹å…³æ³¨æ¶ˆæ¯çŠ¶æ€ç®¡ç†å’Œé”™è¯¯å¤„ç†æœºåˆ¶
   - ä¸æ”¯æŒæœåŠ¡å™¨åˆ‡æ¢åŠŸèƒ½ï¼Œç»Ÿä¸€ä½¿ç”¨Pythonåç«¯

## Quality Standards

- All code must compile without warnings
- Each milestone requires specific verification criteria
- Hot reload must work properly
- Follow the compositional architecture patterns
- Use Hooks for local component state, Riverpod for global state
- Maintain clear separation between presentation, business, and data layers

## Integration Guidelines

### When implementing new features:
1. **Reference Android client** (`/Users/yaotutu/Desktop/code/xiaozhi-android-client`) for implementation patterns
2. **Check Python backend docs** (`/Users/yaotutu/Desktop/code/xiaozhi-esp32-server/main/xiaozhi-server/docs/`) for API specifications
3. **Follow WebSocket protocol** as defined in project memory section above
4. **Maintain session management** with proper device-id and session-id handling
5. **Use consistent error handling** patterns across all network operations

### Audio feature implementation (future milestone):
- Reference Android client's `AudioUtil` class for Opus codec integration
- Follow the audio processing pipeline: `Microphone â†’ PCM16 â†’ Opus â†’ WebSocket`
- Implement real-time audio streaming with 60ms frame duration
- Use 16kHz sample rate, mono channel configuration

### UI/UX consistency:
- Follow Material Design 3 with neumorphism elements
- Maintain gradient backgrounds and floating elements
- Implement smooth animations and transitions
- Ensure responsive design for different screen sizes