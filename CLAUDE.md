# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Lumi Assistant is a Flutter-based intelligent voice assistant client using a milestone-driven development approach. The project is currently in **Phase 1** (text chat functionality) with 10 planned milestones, each requiring user verification before proceeding.

**Current Status**: Milestone 3 (Hello handshake flow) - Successfully completed. Ready for Milestone 4 (Basic UI framework).

## Architecture

The project uses **modern Flutter architecture** rejecting traditional MVVM in favor of:
- **Layered Architecture**: Presentation â†’ Application â†’ Data â†’ Infrastructure
- **Declarative State Management**: flutter_hooks + hooks_riverpod
- **Compositional Design**: Small, focused, reusable components
- **Functional Programming**: Hooks-based approach with pure functions
- **Responsive Design**: Adaptive UI based on screen size and capabilities

Key architectural principles:
- Composition over inheritance
- Single-directional data flow: `User Action â†’ Provider â†’ Service â†’ Repository â†’ DataSource`
- Atomic UI components with clear separation of concerns
- State isolation using Riverpod providers, not traditional Provider pattern
- **Screen-adaptive layouts**: Different UI patterns for large and small screens

## Directory Structure

```
lib/
â”œâ”€â”€ core/                    # Core utilities, constants, services
â”œâ”€â”€ data/                   # Data layer (models, repositories, datasources)
â”œâ”€â”€ domain/                 # Business layer (entities, repository interfaces, use cases)
â””â”€â”€ presentation/           # UI layer (providers, pages, widgets)
    â”œâ”€â”€ pages/               # Page-oriented organization
    â”‚   â””â”€â”€ home/            # Home page and its components
    â”‚       â”œâ”€â”€ home_page.dart
    â”‚       â””â”€â”€ widgets/     # Home page specific widgets
    â”‚           â”œâ”€â”€ background_layer.dart
    â”‚           â”œâ”€â”€ app_status_bar.dart
    â”‚           â”œâ”€â”€ time_panel.dart
    â”‚           â”œâ”€â”€ interaction_layer.dart
    â”‚           â””â”€â”€ floating_actions.dart
    â”œâ”€â”€ widgets/             # Shared widgets across pages
    â””â”€â”€ themes/              # App themes and styling
```

### File Organization Rules

**Page-Oriented Structure**: Each page should have its own directory containing:
- Main page file (e.g., `home_page.dart`)
- `widgets/` subdirectory for page-specific components
- Any page-specific services, models, or utilities

**Shared Components**: Common widgets used across multiple pages go in `presentation/widgets/`

**Benefits**:
- Clear separation of concerns per page
- Easy to locate and maintain page-specific code
- Better scalability for large applications
- Intuitive file organization

## Development Commands

### Environment Setup
```bash
# Check Flutter environment
flutter doctor

# Install dependencies
flutter pub get

# Run the app (preferred device: YT3002)
flutter run -d 1W11833968

# Alternative: List all devices first
flutter devices
```

### Device Configuration
**Primary Testing Device**: YT3002 (Device ID: 1W11833968)
- Platform: Android 7.0 (API 24)
- Architecture: android-arm64
- Screen Resolution: 1280x736 (Landscape-oriented)
- Usage: Primary development and testing device

**Additional Testing**: Test on multiple device types to ensure compatibility:
- Different screen sizes (phone, tablet, landscape devices)
- Various Android versions
- Different pixel densities

When multiple devices are connected, use the `-d 1W11833968` flag to target the YT3002 device for primary testing.

### Quick Commands for YT3002 Device
```bash
# Quick run on YT3002 (preferred device)
flutter run -d 1W11833968

# Hot reload on YT3002
flutter run -d 1W11833968 --hot

# Build and run debug APK on YT3002
flutter run -d 1W11833968 --debug

# Clean build on YT3002
flutter clean && flutter pub get && flutter run -d 1W11833968
```

## Screen Optimization Guidelines

### Responsive Design Principles
**IMPORTANT**: This app should work on various screen sizes and orientations:
- **Approach**: Use responsive design patterns that adapt to different screen sizes
- **Sizing**: Use relative measurements instead of fixed pixel values
- **Layout**: Implement flexible layouts that work across different aspect ratios
- **Testing**: Test on multiple device sizes and orientations

### UI Architecture for Different Screen Modes

#### Large Screen Mode (Priority Implementation)
**Target**: Screens with width >= 600px (portrait) or >= 800px (landscape)

**Features**:
- **Collapsed State**: Small floating icon in bottom-right corner
- **Expanded State**: Left-right split layout (70% chat + 30% character animation)
- **Adaptation Strategy**: Focus on proper center area display, allow margins/padding variations
- **Background**: Supports background concepts, tolerates imperfect edge adaptation

```dart
// Large screen layout parameters
FloatingChatLayoutParams(
  collapsedSize: 100.0,
  expandedWidthRatio: 0.8,
  expandedHeightRatio: 0.6,
  showFullChatInterface: true,
  showCharacterOnRight: true,
  centerContent: true,
)
```

#### Small Screen Mode (Future Implementation)
**Target**: Screens with width < 600px (portrait) or < 800px (landscape)

**Features**:
- **Main Content**: Character animation displayed in center
- **Text Display**: Voice recognition text shown at top
- **Simplified Interface**: No full chat history display
- **Tiny Screen Exception**: Very small screens don't show floating icon on non-chat pages

```dart
// Small screen layout parameters
FloatingChatLayoutParams(
  collapsedSize: 80.0,
  expandedWidthRatio: 0.9,
  expandedHeightRatio: 0.7,
  showFullChatInterface: false,
  showCharacterOnRight: false,
  centerContent: true,
)
```

### Universal UI Design Principles

#### 1. **Avoid Fixed Pixel Sizes**
```dart
// âŒ é”™è¯¯åšæ³•ï¼šä½¿ç”¨å›ºå®šåƒç´ 
Container(
  width: 80,
  height: 80,
  child: Text('ğŸ™‚', style: TextStyle(fontSize: 24)),
)

// âœ… æ­£ç¡®åšæ³•ï¼šä½¿ç”¨ç›¸å¯¹å°ºå¯¸
Container(
  width: containerSize,
  height: containerSize,
  child: Text('ğŸ™‚', style: TextStyle(fontSize: containerSize * 0.5)),
)
```

#### 2. **Emojiå’Œç‰¹æ®Šå­—ç¬¦å¤„ç†**
```dart
// âœ… Emojiæ˜¾ç¤ºæœ€ä½³å®è·µ
Text(
  'ğŸ™‚',
  style: TextStyle(
    fontSize: containerSize * 0.5,  // ç›¸å¯¹äºå®¹å™¨å¤§å°
    height: 1.0,                    // è®¾ç½®è¡Œé«˜ä¸º1.0ï¼Œé¿å…é¢å¤–ç©ºé—´
    color: Colors.white,
  ),
  textAlign: TextAlign.center,
)

// âœ… å®¹å™¨è®¾è®¡æœ€ä½³å®è·µ
Container(
  width: double.infinity,          // å……åˆ†åˆ©ç”¨å¯ç”¨ç©ºé—´
  height: double.infinity,         // å……åˆ†åˆ©ç”¨å¯ç”¨ç©ºé—´
  padding: EdgeInsets.all(4),      // æœ€å°å¿…è¦è¾¹è·
  child: Center(child: emoji),     // å±…ä¸­æ˜¾ç¤º
)
```

#### 3. **å¸ƒå±€ç©ºé—´è®¡ç®—**
```dart
// âœ… ç§‘å­¦çš„ç©ºé—´åˆ†é…
// æ€»ç©ºé—´ = å†…å®¹ç©ºé—´ + å¿…è¦è¾¹è·
// å†…å®¹ç©ºé—´ = å­—ä½“å¤§å° * 1.2 (é¢„ç•™è¡Œé«˜ç©ºé—´)
// å¿…è¦è¾¹è· = æ€»ç©ºé—´ * 0.1 (10%è¾¹è·)

final contentSize = totalSize * 0.8;  // 80%ç”¨äºå†…å®¹
final fontSize = contentSize * 0.6;   // 60%ç”¨äºå­—ä½“
final padding = totalSize * 0.1;      // 10%ç”¨äºè¾¹è·
```

#### 4. **å“åº”å¼è®¾è®¡æ¨¡å¼**
```dart
// âœ… å±å¹•å°ºå¯¸é€‚é…
LayoutBuilder(
  builder: (context, constraints) {
    final isLandscape = constraints.maxWidth > constraints.maxHeight;
    final screenWidth = constraints.maxWidth;
    final screenHeight = constraints.maxHeight;
    
    // æ ¹æ®å±å¹•ç‰¹æ€§é€‰æ‹©å¸ƒå±€
    if (isLandscape) {
      return _buildLandscapeLayout(screenWidth, screenHeight);
    } else {
      return _buildPortraitLayout(screenWidth, screenHeight);
    }
  },
)
```

#### 5. **å­—ä½“å’Œé—´è·ä¼˜åŒ–**
```dart
// âœ… å“åº”å¼å­—ä½“å’Œé—´è·
final textScaleFactor = MediaQuery.of(context).textScaleFactor;
final screenWidth = MediaQuery.of(context).size.width;
final screenHeight = MediaQuery.of(context).size.height;

// åŸºäºå±å¹•å°ºå¯¸çš„å­—ä½“å¤§å°ï¼ˆå–è¾ƒå°å€¼ä¿è¯å…¼å®¹æ€§ï¼‰
final minScreenDimension = math.min(screenWidth, screenHeight);
final baseFontSize = minScreenDimension / 20;  // å“åº”å¼åŸºç¡€å­—ä½“
final scaledFontSize = baseFontSize * textScaleFactor;

// åŸºäºå±å¹•çš„é—´è·
final baseSpacing = minScreenDimension / 100;  // å“åº”å¼é—´è·
```

### å¸¸è§å¸ƒå±€é™·é˜±åŠè§£å†³æ–¹æ¡ˆ

#### 1. **è¾¹è·ç´¯ç§¯é—®é¢˜**
```dart
// âŒ é—®é¢˜ï¼šå¤šå±‚è¾¹è·ç´¯ç§¯
Container(
  padding: EdgeInsets.all(16),     // å¤–å±‚16px
  child: Container(
    padding: EdgeInsets.all(8),    // å†…å±‚8px
    child: Text('å†…å®¹'),           // å®é™…å¯ç”¨ç©ºé—´è¢«å¤§é‡å‹ç¼©
  ),
)

// âœ… è§£å†³ï¼šç»Ÿä¸€è¾¹è·ç®¡ç†
Container(
  padding: EdgeInsets.all(4),      // æœ€å°å¿…è¦è¾¹è·
  child: Center(child: Text('å†…å®¹')), // ä½¿ç”¨Centerè€Œä¸æ˜¯åµŒå¥—Container
)
```

#### 2. **Flexible vs Expandedä½¿ç”¨**
```dart
// âŒ å¯èƒ½å¯¼è‡´å†…å®¹è¢«å‹ç¼©
Flexible(child: Text('ğŸ™‚', style: TextStyle(fontSize: 48)))

// âœ… ç¡®ä¿å†…å®¹å®Œæ•´æ˜¾ç¤º
Expanded(
  child: Center(
    child: Text('ğŸ™‚', style: TextStyle(fontSize: 48, height: 1.0))
  )
)
```

#### 3. **åŠ¨ç”»å’Œè¿‡æ¸¡ä¼˜åŒ–**
```dart
// âœ… å“åº”å¼åŠ¨ç”»å‚æ•°
AnimationController(
  duration: Duration(milliseconds: 300),  // é€‚ä¸­çš„åŠ¨ç”»æ—¶é•¿
  vsync: this,
)

// âœ… ç¼©æ”¾åŠ¨ç”»çš„å®‰å…¨èŒƒå›´
Tween<double>(
  begin: 1.0,
  end: 1.2,  // ä¿å®ˆçš„ç¼©æ”¾èŒƒå›´ï¼Œé€‚ç”¨äºå„ç§å±å¹•
)
```

### æµ‹è¯•å’ŒéªŒè¯æµç¨‹

#### 1. **å¸ƒå±€æµ‹è¯•æ¸…å•**
- [ ] åœ¨å¤šç§åˆ†è¾¨ç‡ä¸‹æµ‹è¯•æ‰€æœ‰ç•Œé¢ï¼ˆåŒ…æ‹¬å¸¸è§çš„ç§»åŠ¨è®¾å¤‡å°ºå¯¸ï¼‰
- [ ] éªŒè¯emojiå’Œç‰¹æ®Šå­—ç¬¦åœ¨ä¸åŒå±å¹•ä¸Šå®Œæ•´æ˜¾ç¤º
- [ ] æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹è¶…å‡ºå±å¹•è¾¹ç•Œ
- [ ] æµ‹è¯•ä¸åŒå­—ä½“å¤§å°è®¾ç½®çš„å…¼å®¹æ€§
- [ ] éªŒè¯æ¨ªå±å’Œç«–å±åˆ‡æ¢ï¼ˆå¦‚æœæ”¯æŒï¼‰
- [ ] æµ‹è¯•ä¸åŒåƒç´ å¯†åº¦è®¾å¤‡çš„æ˜¾ç¤ºæ•ˆæœ

#### 2. **è°ƒè¯•å·¥å…·ä½¿ç”¨**
```dart
// âœ… æ·»åŠ å¸ƒå±€è°ƒè¯•ä¿¡æ¯
print('Screen: ${MediaQuery.of(context).size}');
print('Device pixel ratio: ${MediaQuery.of(context).devicePixelRatio}');
print('Text scale factor: ${MediaQuery.of(context).textScaleFactor}');

// âœ… ä½¿ç”¨Flutter Inspector
// åœ¨Android Studioä¸­ä½¿ç”¨Layout Inspector
// ä½¿ç”¨flutter run --debug è¿›è¡Œè°ƒè¯•
```

#### 3. **æ€§èƒ½è€ƒè™‘**
- é¿å…è¿‡åº¦å¤æ‚çš„å¸ƒå±€åµŒå¥—
- ä½¿ç”¨constæ„é€ å‡½æ•°ä¼˜åŒ–æ€§èƒ½
- åˆç†ä½¿ç”¨Expandedå’ŒFlexible
- é¿å…é¢‘ç¹çš„rebuild

### è®¾è®¡åŸåˆ™æ€»ç»“

1. **å†…å®¹ä¼˜å…ˆ**: å…ˆç¡®å®šå†…å®¹éœ€è¦å¤šå°‘ç©ºé—´ï¼Œå†è®¾è®¡å®¹å™¨
2. **ç›¸å¯¹å°ºå¯¸**: ä½¿ç”¨ç™¾åˆ†æ¯”è€Œä¸æ˜¯å›ºå®šåƒç´ 
3. **å……åˆ†åˆ©ç”¨**: ä½¿ç”¨double.infinityå……åˆ†åˆ©ç”¨å¯ç”¨ç©ºé—´
4. **æœ€å°è¾¹è·**: ä½¿ç”¨æœ€å°å¿…è¦çš„è¾¹è·ï¼Œé¿å…ç©ºé—´æµªè´¹
5. **å®é™…æµ‹è¯•**: åœ¨ç›®æ ‡è®¾å¤‡ä¸Šå®é™…æµ‹è¯•æ‰€æœ‰å¸ƒå±€
6. **å“åº”å¼è®¾è®¡**: è€ƒè™‘ä¸åŒå±å¹•å°ºå¯¸å’Œæ–¹å‘
7. **è¾¹ç•Œæ£€æŸ¥**: ç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½åœ¨å¯è§†åŒºåŸŸå†…

**è®°ä½**: åº”ç”¨åº”è¯¥åœ¨å„ç§å±å¹•å°ºå¯¸ä¸Šéƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚ä½¿ç”¨å“åº”å¼è®¾è®¡åŸåˆ™ï¼Œé¿å…ç¡¬ç¼–ç ç‰¹å®šè®¾å¤‡çš„å‚æ•°ã€‚

### Screen Detection and Adaptation

#### ScreenUtils Class
The `ScreenUtils` class provides screen mode detection and layout parameter calculation:

```dart
// Screen mode detection
final screenMode = ScreenUtils.getScreenMode(context);
final isLargeScreen = ScreenUtils.isLargeScreen(context);
final shouldShow = ScreenUtils.shouldShowFloatingChatIcon(context);

// Layout parameters
final layoutParams = ScreenUtils.getFloatingChatLayoutParams(context);
```

#### Implementation Strategy
1. **Current Focus**: Implement and optimize large screen mode
2. **Future Extension**: Add small screen mode using existing interfaces
3. **Testing**: Verify functionality across different screen sizes
4. **Fallback**: Graceful degradation for edge cases

## Testing
```bash
# Run all tests
flutter test

# Run specific test directory
flutter test test/presentation/providers/

# Generate test coverage
flutter test --coverage
```

### Building
```bash
# Build APK for release
flutter build apk --release

# Build App Bundle
flutter build appbundle --release

# Analyze code
flutter analyze
```

## Backend Integration

**Python Backend Server**: `/Users/yaotutu/Desktop/code/xiaozhi-esp32-server/main/xiaozhi-server`
**WebSocket**: `ws://192.168.110.199:8000/` (å›ºå®šä½¿ç”¨PythonæœåŠ¡å™¨)
**HTTP API**: `http://192.168.110.199:8000/api` (å›ºå®šä½¿ç”¨PythonæœåŠ¡å™¨)
**Authentication**: Bearer Token + Device-ID headers

Message types: `hello` (handshake), `chat` (text), `listen` (voice), `image` (vision)

**æœåŠ¡å™¨é…ç½®è¯´æ˜**ï¼š
- å¼€å‘ç¯å¢ƒï¼šä½¿ç”¨å±€åŸŸç½‘IP `192.168.110.199` (PythonæœåŠ¡å™¨)
- ä¸æ”¯æŒæœåŠ¡å™¨åˆ‡æ¢åŠŸèƒ½ï¼Œç»Ÿä¸€ä½¿ç”¨Pythonåç«¯
- é…ç½®ä½ç½®ï¼š`lib/core/constants/api_constants.dart`

## Reference Implementation

**Android Client**: `/Users/yaotutu/Desktop/code/xiaozhi-android-client`
- Use this Android client as the main reference for implementation patterns
- Follow similar WebSocket handling and UI interaction patterns
- Reference authentication and message handling approaches

## Project Memory and Context

### Reference Projects Overview

#### Android Client (`/Users/yaotutu/Desktop/code/xiaozhi-android-client`)
**Project Type**: Flutter application (not native Android)
**Architecture**: Provider-based state management with service layer pattern
**Key Features**:
- Real-time WebSocket communication with event-driven architecture
- Opus audio codec integration for voice processing
- Multi-conversation management with persistent storage
- Material Design 3 UI with neumorphism elements
- Voice call interface with audio visualization

**Key Implementation Patterns to Reference**:
```dart
// Event-driven WebSocket architecture
enum XiaozhiEventType { connected, disconnected, message, error, binaryMessage }

// Service layer pattern
class XiaozhiService {
  static final XiaozhiService instance = XiaozhiService._internal();
  late XiaozhiWebSocketManager _webSocketManager;
}

// Audio processing pipeline
class AudioUtil {
  static const int SAMPLE_RATE = 16000;
  static const int CHANNELS = 1;
  static const int FRAME_DURATION = 60; // milliseconds
}
```

#### Python Backend (`/Users/yaotutu/Desktop/code/xiaozhi-esp32-server/main/xiaozhi-server`)
**Project Type**: AsyncIO-based Python server with comprehensive AI integration
**Architecture**: Provider pattern with plugin system for AI services
**Core Features**:
- WebSocket server for real-time audio streaming
- HTTP API for OTA updates and vision analysis
- Multi-modal AI: ASR, LLM, TTS, Vision, VAD
- IoT device control with MCP protocol
- Function calling and plugin system

**API Documentation Source**: All interface specifications are derived from this backend's `/docs` directory

### WebSocket Protocol (from Python Backend)

#### Connection Flow:
1. **Client Connection**: `ws://192.168.110.199:8000/xiaozhi/v1/`
2. **Authentication**: Headers (`device-id`, `Authorization: Bearer token`)
3. **Handshake**: `hello` message exchange with session management
4. **Audio Streaming**: Binary Opus frames + JSON text messages

#### Message Types:
```json
// Client Hello
{
  "type": "hello",
  "version": 1,
  "transport": "websocket",
  "audio_params": {
    "format": "opus",
    "sample_rate": 16000,
    "channels": 1,
    "frame_duration": 60
  }
}

// Server Hello Response
{
  "type": "hello",
  "session_id": "uuid-generated-by-server",
  "version": 1,
  "transport": "websocket",
  "audio_params": { ... }
}

// Listen Control
{
  "type": "listen",
  "state": "start|stop|detect",
  "mode": "auto|manual",
  "text": "optional text input"
}

// TTS Response
{
  "type": "tts",
  "state": "start|sentence_start|sentence_end|stop",
  "text": "Generated response text",
  "session_id": "uuid"
}

// STT Recognition
{
  "type": "stt",
  "text": "Recognized speech text",
  "confidence": 0.95,
  "is_final": true,
  "session_id": "uuid"
}
```

### HTTP API Endpoints (from Python Backend)

#### OTA Updates:
```http
POST /xiaozhi/ota/
Headers: device-id, Authorization
Body: {"application": {"version": "1.0.0", "build": "timestamp"}}

Response: {
  "server_time": {"timestamp": 1699123456789, "timezone_offset": 480},
  "websocket": {"url": "ws://192.168.110.199:8000/xiaozhi/v1/"}
}
```

#### Vision Analysis:
```http
POST /mcp/vision/explain
Content-Type: multipart/form-data
Headers: Authorization, Device-Id
Form: question (text), image (file)

Response: {
  "success": true,
  "action": "RESPONSE",
  "response": "Image analysis result..."
}
```

### Audio Processing Specifications (from both projects)

#### Audio Format:
- **Codec**: Opus (libopus)
- **Sample Rate**: 16kHz
- **Channels**: Mono (1 channel)
- **Frame Duration**: 60ms
- **Bitrate**: Adaptive (8-64 kbps)

#### Processing Pipeline:
```
Microphone â†’ PCM16 â†’ Opus Encoder â†’ WebSocket Binary â†’ Server
Server â†’ Opus Audio â†’ WebSocket Binary â†’ Opus Decoder â†’ PCM â†’ Speaker
```

### Integration Patterns for Flutter

#### WebSocket Service Pattern (from Android Client):
```dart
class WebSocketService {
  late WebSocket _webSocket;
  final StreamController<XiaozhiEvent> _eventController = StreamController.broadcast();
  
  Future<void> connect(String url, Map<String, String> headers) async {
    _webSocket = await WebSocket.connect(url, headers: headers);
    _webSocket.listen(_onMessage, onError: _onError);
  }
  
  void sendHello() {
    final hello = {
      'type': 'hello',
      'version': 1,
      'transport': 'websocket',
      'audio_params': {
        'format': 'opus',
        'sample_rate': 16000,
        'channels': 1,
        'frame_duration': 60
      }
    };
    _webSocket.add(jsonEncode(hello));
  }
}
```

#### Provider Pattern (from Backend):
```dart
// AI Service Integration
abstract class ASRProvider {
  Future<String> speechToText(List<int> opusData, String sessionId);
}

abstract class LLMProvider {
  Stream<String> generateResponse(String sessionId, List<Map<String, dynamic>> dialogue);
}

abstract class TTSProvider {
  Future<Uint8List> textToSpeech(String text);
}
```

### Development Priorities (based on reference implementations)

#### Phase 1: Foundation (Current)
- âœ… WebSocket connection with authentication
- âœ… Basic hello handshake protocol
- âœ… Text message exchange
- âœ… Session management

#### Phase 2: Audio Integration
- ğŸ”„ Opus audio recording/encoding
- ğŸ”„ Audio streaming to server
- ğŸ”„ TTS audio reception/playback
- ğŸ”„ Real-time audio processing

#### Phase 3: Advanced Features
- â¸ï¸ Vision analysis integration
- â¸ï¸ Function calling display
- â¸ï¸ IoT device control UI
- â¸ï¸ Multi-conversation management

#### Phase 4: Production Features
- â¸ï¸ Error handling and reconnection
- â¸ï¸ Offline mode support
- â¸ï¸ Performance monitoring
- â¸ï¸ Voice call interface

### Key Learnings from Reference Projects

1. **Event-Driven Architecture**: Both projects use listener patterns for real-time communication
2. **Service Layer Separation**: Clear separation between UI and business logic
3. **Robust Audio Processing**: Comprehensive audio pipeline with proper resource management
4. **Session Management**: Proper handling of server sessions and reconnection
5. **Error Handling**: Graceful degradation and user-friendly error messages

### Migration Path (Android Client â†’ Current Flutter)

**State Management**: `Provider` â†’ `hooks_riverpod` (already implemented)
**Architecture**: `Traditional` â†’ `Clean Architecture` (partially implemented)
**Audio Processing**: `Simple` â†’ `Comprehensive Opus Pipeline` (to be implemented)
**UI Pattern**: `Material Design` â†’ `Material Design 3 + Neumorphism` (partially implemented)

## Milestone-Driven Development

**Critical**: This project follows strict milestone verification:
1. Each milestone must be fully completed before moving to next
2. User verification required after each milestone
3. No feature should be started without completing current milestone
4. All progress tracked in `docs/planning/MILESTONE_TRACKING.md`

**é‡Œç¨‹ç¢‘å®ŒæˆçŠ¶æ€**:
- âœ… é‡Œç¨‹ç¢‘1ï¼šé¡¹ç›®åŸºç¡€æ­å»º - å·²å®Œæˆ
- âœ… é‡Œç¨‹ç¢‘2ï¼šç½‘ç»œè¿æ¥åŸºç¡€ - å·²å®Œæˆ  
- âœ… é‡Œç¨‹ç¢‘3ï¼šHelloæ¡æ‰‹æµç¨‹ - å·²å®Œæˆ
- âœ… é‡Œç¨‹ç¢‘4ï¼šåŸºç¡€UIæ¡†æ¶ - å·²å®Œæˆ
- âœ… é‡Œç¨‹ç¢‘5ï¼šèŠå¤©ç•Œé¢åŸºç¡€ - å·²å®Œæˆ
- âœ… é‡Œç¨‹ç¢‘6ï¼šæ–‡å­—æ¶ˆæ¯å‘é€ - å·²å®Œæˆ
- â¸ï¸ é‡Œç¨‹ç¢‘7ï¼šLLMå“åº”å¤„ç† - ç­‰å¾…ä¸­

**å½“å‰çŠ¶æ€**: é‡Œç¨‹ç¢‘6å·²å®Œæˆï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µå¼€å‘

**ä¸‹ä¸€é˜¶æ®µä»»åŠ¡**ï¼ˆé‡Œç¨‹ç¢‘7ï¼šLLMå“åº”å¤„ç†ï¼‰:
- å®ç°æœåŠ¡å™¨å“åº”æ¶ˆæ¯æ¥æ”¶å’Œæ˜¾ç¤º
- å®Œå–„èŠå¤©æ¶ˆæ¯æµç®¡ç†
- å¤„ç†ä¸åŒç±»å‹çš„æœåŠ¡å™¨å“åº”
- å®ç°æ¶ˆæ¯çŠ¶æ€è¿½è¸ªå’Œé”™è¯¯å¤„ç†

## Code Patterns

### State Management
```dart
// Riverpod Provider with Hooks
final chatProvider = StateNotifierProvider<ChatNotifier, ChatState>((ref) {
  return ChatNotifier(ref.read(webSocketServiceProvider));
});

// Hook Consumer Widget
class ChatPage extends HookConsumerWidget {
  Widget build(BuildContext context, WidgetRef ref) {
    final chatState = ref.watch(chatProvider);
    final controller = useTextEditingController();
    // ...
  }
}
```

### Error Handling
Use custom exception types (`NetworkException`, `WebSocketException`) with centralized error handling via `ErrorHandler` class.

### File Naming
- snake_case for files: `chat_service.dart`
- PascalCase for classes: `ChatService`
- camelCase for variables/methods: `sendMessage`

## Documentation Structure

Important docs are organized in `docs/`:
- `planning/` - Project plans and milestone tracking
- `architecture/` - Technical architecture and specifications  
- `frontend/` - Development guidelines and best practices

**Always check milestone status** in `docs/planning/MILESTONE_TRACKING.md` before making changes.

### é¡¹ç›®è®°å¿†é‡è¦æé†’

1. **å‚è€ƒé¡¹ç›®ä½ç½®**ï¼š
   - Androidå®¢æˆ·ç«¯ï¼š`/Users/yaotutu/Desktop/code/xiaozhi-android-client`
   - Pythonåç«¯ï¼š`/Users/yaotutu/Desktop/code/xiaozhi-esp32-server/main/xiaozhi-server`

2. **APIæ–‡æ¡£æ¥æº**ï¼š
   - æ‰€æœ‰æ¥å£è§„èŒƒéƒ½æ¥è‡ªPythonåç«¯é¡¹ç›®çš„`docs/`ç›®å½•
   - WebSocketåè®®å’ŒHTTP APIçš„è¯¦ç»†å®šä¹‰åœ¨ä¸Šé¢çš„é¡¹ç›®è®°å¿†ä¸­

3. **å¼€å‘ä¼˜å…ˆçº§**ï¼š
   - å½“å‰é˜¶æ®µä¸»è¦å…³æ³¨æ–‡æœ¬èŠå¤©åŠŸèƒ½çš„å®Œå–„
   - éŸ³é¢‘åŠŸèƒ½åœ¨åç»­é˜¶æ®µå®ç°ï¼Œéœ€è¦å‚è€ƒAndroidå®¢æˆ·ç«¯çš„OpuséŸ³é¢‘å¤„ç†
   - å¤šæ¨¡æ€åŠŸèƒ½ï¼ˆè§†è§‰ã€IoTæ§åˆ¶ï¼‰å°†åœ¨æœ€åå®ç°

4. **æŠ€æœ¯æ¶æ„å¯¹é½**ï¼š
   - å½“å‰é¡¹ç›®ä½¿ç”¨çš„hooks_riverpodæ¯”Androidå®¢æˆ·ç«¯çš„Provideræ›´ç°ä»£
   - ä½†éœ€è¦å‚è€ƒAndroidå®¢æˆ·ç«¯çš„WebSocketäº‹ä»¶é©±åŠ¨æ¶æ„
   - éŸ³é¢‘å¤„ç†ç®¡é“éœ€è¦å®Œå…¨éµå¾ªAndroidå®¢æˆ·ç«¯çš„æ¨¡å¼

5. **å½“å‰å¼€å‘é‡ç‚¹**ï¼š
   - é‡Œç¨‹ç¢‘6å·²å®Œæˆæ–‡æœ¬æ¶ˆæ¯å‘é€åŠŸèƒ½
   - ä¸‹ä¸€æ­¥éœ€è¦å®ç°æœåŠ¡å™¨å“åº”æ¶ˆæ¯çš„å®Œæ•´å¤„ç†
   - é‡ç‚¹å…³æ³¨æ¶ˆæ¯çŠ¶æ€ç®¡ç†å’Œé”™è¯¯å¤„ç†æœºåˆ¶
   - ä¸æ”¯æŒæœåŠ¡å™¨åˆ‡æ¢åŠŸèƒ½ï¼Œç»Ÿä¸€ä½¿ç”¨Pythonåç«¯

## Quality Standards

- All code must compile without warnings
- Each milestone requires specific verification criteria
- Hot reload must work properly
- Follow the compositional architecture patterns
- Use Hooks for local component state, Riverpod for global state
- Maintain clear separation between presentation, business, and data layers

## Integration Guidelines

### When implementing new features:
1. **Reference Android client** (`/Users/yaotutu/Desktop/code/xiaozhi-android-client`) for implementation patterns
2. **Check Python backend docs** (`/Users/yaotutu/Desktop/code/xiaozhi-esp32-server/main/xiaozhi-server/docs/`) for API specifications
3. **Follow WebSocket protocol** as defined in project memory section above
4. **Maintain session management** with proper device-id and session-id handling
5. **Use consistent error handling** patterns across all network operations

### Audio feature implementation (future milestone):
- Reference Android client's `AudioUtil` class for Opus codec integration
- Follow the audio processing pipeline: `Microphone â†’ PCM16 â†’ Opus â†’ WebSocket`
- Implement real-time audio streaming with 60ms frame duration
- Use 16kHz sample rate, mono channel configuration

### UI/UX consistency:
- Follow Material Design 3 with neumorphism elements
- Maintain gradient backgrounds and floating elements
- Implement smooth animations and transitions
- Ensure responsive design for different screen sizes